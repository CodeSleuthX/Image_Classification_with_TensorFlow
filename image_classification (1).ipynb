{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqRmMvPLDWXQ"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "e-YBnbRss3nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "SW2nbwzuGFkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning Rate Scheduler\n",
        "def lr_schedule(epoch):\n",
        "    return 0.001 * (0.1 ** int(epoch / 10))\n",
        "\n",
        "lr_callback = LearningRateScheduler(lr_schedule)"
      ],
      "metadata": {
        "id": "wByhBbLUGXhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture with Batch Normalization\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(10)\n",
        "])"
      ],
      "metadata": {
        "id": "vbJSWiJYGdei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropout for Regularization\n",
        "model.add(Dropout(0.25))"
      ],
      "metadata": {
        "id": "FO04sEBYGiJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "kabFdoW2JdUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with Data Augmentation and Learning Rate Scheduler\n",
        "history = model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=32),\n",
        "    epochs=50,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[lr_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOWLVppCJgM9",
        "outputId": "192fc68f-fca9-4a07-f9eb-b8ebf13c1e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 67s 42ms/step - loss: 1.7639 - accuracy: 0.1072 - val_loss: 1.5167 - val_accuracy: 0.1441 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 68s 43ms/step - loss: 1.4811 - accuracy: 0.1169 - val_loss: 1.1247 - val_accuracy: 0.1201 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 1.3635 - accuracy: 0.1219 - val_loss: 1.1758 - val_accuracy: 0.1790 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "id": "NDd91MIOth-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"cifar10_image_classifier.h5\")"
      ],
      "metadata": {
        "id": "EfPZp1fCtjUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oKF2Uqqjtk_8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}